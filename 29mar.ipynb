{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a1f4b2-e286-43a8-9ba8-6f3c509b75bd",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "ans->Lasso Regression is a powerful technique for linear regression that combines feature selection with regularization. It is particularly valuable when you have high-dimensional data and want to create simpler models by selecting only the most relevant features.\n",
    "\n",
    " It differs from other techniques by automatically driving some coefficients to zero, making it suitable for feature selection and creating simpler, more interpretable models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd332a-ce22-4d0d-b120-7fcd6bf1fecd",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "ans->the main advantage of using Lasso Regression in feature selection is its automatic and efficient process of identifying and selecting the most important predictors while setting others to zero. This simplifies the model, reduces overfitting, improves performance, and enhances interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10c312-8c04-49f1-aa31-17e04fe9a1ac",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "ans->interpreting the coefficients in Lasso Regression involves considering the sign, magnitude, significance, and the effect of regularization on individual coefficients. Additionally, you can assess the sparsity and simplicity of the model due to Lasso's feature selection capability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f7786-1b51-4c34-88bc-ac6e1f153fb0",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "\n",
    "ans-> the primary tuning parameter in Lasso Regression is the regularization strength (alpha or lambda). By adjusting this parameter, you control the model's complexity, feature selection, bias-variance trade-off, and overfitting. Selecting the appropriate alpha value depends on the specific dataset and the balance you want to strike between model simplicity and predictive accuracy. Cross-validation is a valuable tool for finding the optimal alpha value for a given problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e97be-7da5-4aa1-850d-825bf1deeb4a",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "ans->Lasso Regression is primarily designed for linear relationships but can be adapted for non-linear regression problems by using techniques such as creating polynomial features, transforming predictors, applying piecewise linear models, using kernel methods, using spline models, or considering specialized variants like Non-Linear Lasso (NLasso). These methods enable Lasso Regression to capture non-linear patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be6730-dc90-44b4-a8ea-a4a8abe7b17c",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "ans->the main differences between Ridge Regression and Lasso Regression are:\n",
    "\n",
    "Ridge uses L2 regularization, while Lasso uses L1 regularization.\n",
    "\n",
    "Ridge reduces coefficient magnitudes but doesn't set any to zero, while Lasso reduces magnitudes and explicitly sets some coefficients to zero for feature selection.\n",
    "\n",
    "Ridge is useful for mitigating multicollinearity, while Lasso is valuable for feature selection and creating sparse models. Your choice depends on your specific needs and data characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6058da7-b20a-43ac-bf4a-dc0b83af59af",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "ans->Lasso Regression can handle multicollinearity by selecting one predictor from a group of correlated predictors and driving the coefficients of the others to zero. This simplifies the model, improves interpretability, and addresses multicollinearity to some extent. However, it doesn't completely eliminate multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f54c32-ee41-4d40-b1e6-2517bf85af14",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "ans->we can choose the optimal value of the regularization parameter (lambda) in Lasso Regression by:\n",
    "\n",
    "1. Selecting a range of lambda values.\n",
    "2. Splitting the data into training, validation, and test sets.\n",
    "3. Standardizing features.\n",
    "4. Fitting Lasso models for each lambda on the training set.\n",
    "5. Applying k-fold cross-validation on the training set.\n",
    "6. Selecting the lambda with the best cross-validated performance.\n",
    "7. Testing the final model on the test set for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abed30-07da-415f-8b77-fe5b74328972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
