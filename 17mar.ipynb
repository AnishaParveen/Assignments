{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b459a4-808d-420f-9c68-3440a0f0e317",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values.\n",
    "\n",
    "ans->Missing values in a dataset are data points that are not available for some variables.Handling them is essential because they can lead to biased results, loss of information, and errors in data analysis and machine learning. Some algorithms that are not affected by missing values include decision trees, random forests, k-nearest neighbors, naive Bayes, PCA, XGBoost, LightGBM, and certain neural network architectures. However, often, it's beneficial to use imputation techniques to fill in missing values for better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c288f33-e59f-4584-b2a6-eccbf01480f5",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "\n",
    "ans->1.Removing Rows with Missing Values (Listwise Deletion)\n",
    "\n",
    "2.Imputation with Mean, Median, or Mode\n",
    "\n",
    "3.Forward Fill and Backward Fill (Time Series Data)\n",
    "\n",
    "4.Interpolation\n",
    "\n",
    "5.Imputation with a Constant Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1354c03-81bd-4a49-8de8-ae5522c68d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "#2\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)\n",
    "df['B'].fillna(df['B'].median(), inplace=True)\n",
    "\n",
    "#3\n",
    "# Forward fill missing values\n",
    "df_ffill = df.ffill()\n",
    "\n",
    "# Backward fill missing values\n",
    "df_bfill = df.bfill()\n",
    "\n",
    "#4\n",
    "df_interp = df.interpolate()\n",
    "\n",
    "#5\n",
    "df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf83a4-f0fa-48f1-933a-f3a4f8920eb7",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "ans->Imbalanced data refers to a situation in a classification problem where the distribution of classes is highly skewed, with one class significantly outnumbering the others. For example, in a binary classification problem, if Class A has 95% of the data, and Class B has only 5%, it's an imbalanced dataset.\n",
    "\n",
    "If imbalanced data is not handled:\n",
    "\n",
    "1.Biased Models: Machine learning models tend to be biased towards the majority class, leading to poor predictive performance for minority classes.\n",
    "\n",
    "2.Misclassification: The model may have high accuracy on the majority class but perform poorly on the minority class, leading to misclassification and missed important outcomes.\n",
    "\n",
    "3.Loss of Information: The minority class may contain valuable insights or rare events that are crucial to capture. Ignoring them can result in a loss of critical information.\n",
    "\n",
    "4.Model Evaluation Issues: Traditional accuracy metrics can be misleading. Models may appear highly accurate due to the dominant class, even though they perform poorly on the minority class.\n",
    "\n",
    "To handle imbalanced data, techniques such as resampling (oversampling minority or undersampling majority class), using different evaluation metrics (precision, recall, F1-score), and employing advanced algorithms like ensemble methods or cost-sensitive learning are often applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5045a4c-47d8-4b56-b605-6aef8a2f416a",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required.\n",
    "\n",
    "ans->Up-sampling (Over-sampling):\n",
    "Up-sampling involves increasing the number of instances in the minority class to balance the class distribution. This is typically done by duplicating existing data points or generating synthetic data points. The goal is to provide the model with more examples of the minority class.\n",
    "\n",
    "Example when up-sampling is required:\n",
    "Imagine a fraud detection system where the majority of transactions are non-fraudulent (e.g., 95% of transactions), and only a small fraction are fraudulent (e.g., 5%). In this case, you'd up-sample the minority class (fraudulent transactions) to improve the model's ability to detect fraud.\n",
    "\n",
    "Down-sampling (Under-sampling):\n",
    "Down-sampling involves reducing the number of instances in the majority class to balance the class distribution. This is typically done by randomly removing some data points from the majority class. The goal is to prevent the model from being biased toward the majority class.\n",
    "\n",
    "Example when down-sampling is required:\n",
    "Suppose you're building a medical diagnosis model where healthy patients greatly outnumber patients with a rare disease. In this case, you'd down-sample the majority class (healthy patients) to ensure the model doesn't overwhelmingly predict healthy outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c3c1c-aac9-40be-8529-0c72b6f2c8d8",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "ans->Data Augmentation: Data augmentation is a technique to artificially increase the size of a dataset by applying transformations to the existing data, often used in image and text data to improve model generalization.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique): SMOTE is a data augmentation technique for addressing class imbalance in classification tasks. It creates synthetic instances in the minority class by interpolating between existing instances and their neighbors, helping to balance the class distribution and improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe335c-cfb7-4287-a756-7d146bf15a08",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "ans->Outliers are data points that significantly differ from the majority of data in a dataset. They can be unusually high or low values, or they may exhibit patterns inconsistent with the rest of the data.\n",
    "\n",
    "It is essential to handle outliers because they can:\n",
    "\n",
    "Skew Statistical Measures: Outliers can distort summary statistics like mean and standard deviation, leading to inaccurate interpretations of the data.\n",
    "\n",
    "Impact Model Performance: Outliers can adversely affect the performance of machine learning models, making them less accurate or robust.\n",
    "\n",
    "Mislead Analysis: Outliers can mislead data analysis and lead to incorrect conclusions or insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83772fb9-7c18-4677-bc10-55f83ecaf20d",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "ans->To handle missing data in customer analysis:\n",
    "\n",
    "1.Use data imputation methods like mean, median, or regression to fill in missing values.\n",
    "\n",
    "2.Consider advanced techniques like K-NN imputation or multiple imputation for better accuracy.\n",
    "\n",
    "3.Remove rows or columns with excessive missing data if it doesn't significantly impact the analysis.\n",
    "\n",
    "The choice depends on data characteristics and analysis goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6254f94-a8d9-4a90-a162-2c70122a970e",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?\n",
    "\n",
    "ans->To determine if missing data is missing at random or follows a pattern:\n",
    "\n",
    "1. Visualize missing data using heatmaps or histograms.\n",
    "2. Compare summary statistics for missing and non-missing data.\n",
    "3. Analyze correlations between missingness in different variables.\n",
    "4. Conduct hypothesis tests to check for significant associations.\n",
    "5. Understand the missing data mechanism (MCAR, MAR, NMAR).\n",
    "6. Seek domain expertise for insights.\n",
    "7. Experiment with different imputation methods based on hypotheses.\n",
    "8. Explore subsets or time periods for changing patterns.\n",
    "9. Use machine learning to identify important variables.\n",
    "10. Perform sensitivity analyses to assess robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66974611-366a-4b53-bb37-f81101dc3764",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "ans->To evaluate a machine learning model on an imbalanced medical diagnosis dataset:\n",
    "\n",
    "1. Use metrics like precision, recall, F1-score, AUC-ROC, and AUC-PR.\n",
    "2. Balance data with resampling or stratified sampling.\n",
    "3. Consider cost-sensitive learning and ensemble methods.\n",
    "4. Adjust classification thresholds to meet specific needs.\n",
    "5. Perform feature engineering and consult domain experts.\n",
    "6. Conduct a cost-benefit analysis.\n",
    "7. Explore imbalanced learning libraries.\n",
    "8. Collaborate with medical experts for clinical alignment.\n",
    "9. Collect more data for the minority class if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc01222-3eee-4d8f-a819-590ec9f46136",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?\n",
    "\n",
    "ans->To balance an unbalanced dataset with mostly satisfied customers:\n",
    "\n",
    "1. Use random under-sampling to remove random samples from the majority class.\n",
    "2. Employ cluster-based under-sampling to group similar samples and then down-sample.\n",
    "3. Identify and remove Tomek links between classes.\n",
    "4. Apply Edited Nearest Neighbors (ENN) to remove inconsistent samples.\n",
    "5. Combine techniques like ENN with random under-sampling.\n",
    "6. Use NearMiss to select majority class samples closer to the minority class.\n",
    "7. Employ Condensed Nearest Neighbor (CNN) to represent the majority class.\n",
    "8. Repeatedly apply random under-sampling for robustness.\n",
    "9. Consider ensemble methods like EasyEnsemble or BalanceCascade.\n",
    "10. Combine over-sampling (e.g., SMOTE) with under-sampling (e.g., ENN or Tomek links) for a balanced dataset.\n",
    "\n",
    "Select the method based on your dataset's characteristics and evaluate its impact on model performance and information loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f6b6a-1cce-4b48-b37d-f4e303453ce0",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?\n",
    "\n",
    "ans->To balance an imbalanced dataset with a rare event:\n",
    "\n",
    "1. Use random over-sampling by duplicating minority class samples.\n",
    "2. Apply SMOTE to generate synthetic samples near existing minority class points.\n",
    "3. Consider ADASYN for adaptive synthetic sampling.\n",
    "4. Explore variations like Borderline-SMOTE or SMOTE-ENN.\n",
    "5. Use SOT for an ensemble-based approach.\n",
    "6. Combine random over-sampling with Tomek links removal (ROST).\n",
    "7. Employ Kernel Density Estimation (KDE) for synthetic sample generation.\n",
    "8. Explore ensemble methods like EasyEnsemble or BalanceCascade.\n",
    "9. Collect more data for the rare event if possible.\n",
    "\n",
    "Select the method based on your dataset's characteristics and assess its impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba2153-c895-4858-b898-39fdfbcff569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
