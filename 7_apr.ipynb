{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a0f28d-33b7-4e1a-8b16-cde05589643f",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "ans->polynomial functions are a specific type of transformation used within kernel functions in machine learning algorithms like SVMs. Kernel functions encompass various transformations beyond polynomials and are used to compute the similarity between data points in original or transformed feature spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b564de-8701-4a04-bc04-c461171d9f95",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "ans->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dede382b-14a7-4dbf-a618-f2d2dfbf4528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_classifier = SVC(kernel='poly', degree=3)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81816117-4c61-460f-abba-2f26a2833e0d",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "ans->Increasing the value of epsilon generally leads to an increase in the number of support vectors in SVR. This is because a larger epsilon allows for a wider margin of tolerance, allowing more data points to fall within the margin without incurring a penalty. Consequently, more data points become support vectors as they contribute to defining the margin or are located within it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd90aaf-0235-4771-addc-7135b31d9d49",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "ans->Kernel Function:\n",
    "\n",
    "The kernel function determines the mapping of input data into a higher-dimensional space.\n",
    "Different kernel functions (e.g., linear, polynomial, radial basis function (RBF), sigmoid) offer different ways of capturing non-linear relationships in the data.\n",
    "\n",
    "Example: If the relationship between input features and target values is non-linear, using a polynomial or RBF kernel might improve model performance compared to a linear kernel.\n",
    "\n",
    "\n",
    "C Parameter:\n",
    "\n",
    "The C parameter controls the trade-off between maximizing the margin and minimizing the training error.\n",
    "A smaller C value allows for a larger margin but may lead to more training errors (soft margin).\n",
    "A larger C value penalizes training errors more heavily, resulting in a smaller margin but potentially better performance on the training data (hard margin).\n",
    "\n",
    "Example: If the training data contains outliers or noise, increasing C might help the model focus more on correctly classifying data points.\n",
    "\n",
    "\n",
    "Epsilon Parameter:\n",
    "\n",
    "The epsilon parameter (Îµ) determines the margin of tolerance for deviations from the actual target values in SVR.\n",
    "It defines an epsilon-insensitive tube around the predicted function values, within which no penalty is incurred.\n",
    "Increasing epsilon widens the tube, allowing for larger deviations from the target values without incurring a penalty.\n",
    "\n",
    "Example: If the target values have some inherent variability or uncertainty, increasing epsilon can make the model more tolerant to deviations and generalize better to unseen data.\n",
    "\n",
    "\n",
    "Gamma Parameter:\n",
    "\n",
    "The gamma parameter defines the influence of a single training example, affecting the \"reach\" of the kernel function.\n",
    "A smaller gamma value makes the decision boundary smoother and more linear, while a larger gamma value makes it more irregular and captures fine-grained details of the training data.\n",
    "It essentially controls the shape of the decision boundary.\n",
    "\n",
    "Example: If the training data is highly complex or noisy, decreasing gamma can help prevent overfitting by creating a smoother decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756e758-e4cf-4417-8c89-6ee9b0e2875e",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd837e66-d3f8-4505-a6b8-836677387557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Best Parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['iris_svc_classifier.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Create an instance of the SVC classifier and train it on the training data\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 5: Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "# Step 6: Evaluate the performance of the classifier using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Step 7: Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['rbf', 'linear', 'poly']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Step 8: Train the tuned classifier on the entire dataset\n",
    "best_svc = grid_search.best_estimator_\n",
    "best_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 9: Save the trained classifier to a file\n",
    "joblib.dump(best_svc, 'iris_svc_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824750b1-758e-418b-bc36-a247b237b65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
