{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4aa1d0-dbe7-42b2-b8f3-82454d97ee3a",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "ans->Web scraping is an automatic method to obtain large amounts of data from websites.\n",
    "\n",
    "\n",
    "Web Scraping can be used to periodically extract data of products from various e-commerce websites like Amazon, eBay, Google Shopping etc.\n",
    "\n",
    "1. Price Monitoring\n",
    "\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64cfa2-329a-4a62-8963-aba81b9d6020",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "ans->There are several methods for web scraping, including manual scraping, web scraping tools, APIs, browser extensions, headless browsers, DOM parsing, and machine learning. Each method has its advantages and disadvantages, and the choice of method depends on the specific requirements of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27226a-2b8b-4097-9cca-6fd44e28006f",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "ans->Beautiful Soup is a python package which allows us to pull data out of HTML and XML documents.\n",
    "\n",
    "It is commonly used because it provides a simple way to parse HTML and XML documents, handles complex data, makes it easy to navigate and search through the parsed data, is robust and can handle poorly formatted HTML and XML documents, can be easily integrated with other Python libraries, and is open-source. Overall, Beautiful Soup is a versatile tool for web scraping that is essential for many web scraping projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439db39-2f23-42ff-9a74-36c179dafc23",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "ans->Flask is a lightweight framework to build web api's. We use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b8015-8b38-466e-954c-73b23f44d505",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "ans->CodePipeline and Elastic Beanstalk we used in this project.\n",
    "\n",
    "CodePipeline is an AWS service that automates the build, test, and deployment phases of software release processes. It enables continuous delivery of code changes, integrates with other AWS services, provides customizable workflows, visibility and control over the release process, and secure release management.\n",
    "\n",
    "Elastic Beanstalk is an AWS service that simplifies the deployment and management of web applications. It provides easy deployment, scalability, customization, monitoring and logging capabilities, and integration with other AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b95c8-c44b-4953-8271-0ae0dfca4f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e74e4f-ffb4-4122-a09c-9b1c38ff64c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df90a52-05e1-4a50-a166-a558c7861564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5196c7-7345-4add-94a8-2f4a77400bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
